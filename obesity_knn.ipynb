{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c06457f",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor(KNN) Classifier\n",
    "K-Nearest Neighbors is a supervised machine learning algorithm mainly used for classification. The way it works is finding the \"k\" closest points or \"neighbors\" to a given input and makes a predictions based on the majority class or the average value in case of regresion. \n",
    "In the k-Nearest Neighbours algorithm k is just a number that tells the algorithm how many nearby points or neighbors to look at when it makes a decision.\n",
    "### Distance Metrics Used in KNN Algorithm\n",
    "KNN uses distance metrics to identify nearest neighbor, these neighbors are used for classification and regression task. To identify nearest neighbor we use below distance metrics:\n",
    "\n",
    "1. Euclidean Distance: the straight-line distance between two points.\n",
    "2. Manhattan Distance: the total distance you would travel if you could only move along horizontal and vertical lines like a grid or city.\n",
    "3. Minkowski Distance: is like a family of distances that in some cases includes euclidean and manhattan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d38e013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
      "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
      "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
      "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
      "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
      "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
      "\n",
      "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
      "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
      "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
      "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
      "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
      "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
      "\n",
      "                  MTRANS  \n",
      "0  Public_Transportation  \n",
      "1  Public_Transportation  \n",
      "2  Public_Transportation  \n",
      "3                Walking  \n",
      "4  Public_Transportation  \n",
      "            NObeyesdad\n",
      "0        Normal_Weight\n",
      "1        Normal_Weight\n",
      "2        Normal_Weight\n",
      "3   Overweight_Level_I\n",
      "4  Overweight_Level_II\n",
      "Columnas categóricas: ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
      "Columnas numéricas: ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report, accuracy_score\n",
    "\n",
    "# 1. Cargar dataset\n",
    "dataset = fetch_ucirepo(id=544)\n",
    "\n",
    "X = dataset.data.features\n",
    "y = dataset.data.targets\n",
    "\n",
    "# Verifica las primeras filas\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "\n",
    "# 2. Identificar columnas categóricas y numéricas\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Columnas categóricas: {categorical_cols}\")\n",
    "print(f\"Columnas numéricas: {numerical_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f475d82",
   "metadata": {},
   "source": [
    "# Advantages of KNN\n",
    "Simple to use: Easy to understand and implement.\n",
    "No training step: No need to train as it just stores the data and uses it during prediction.\n",
    "Few parameters: Only needs to set the number of neighbors (k) and a distance method.\n",
    "Versatile: Works for both classification and regression problems.\n",
    "# Disadvantages of KNN\n",
    "Slow with large data: Needs to compare every point during prediction.\n",
    "Struggles with many features: Accuracy drops when data has too many features.\n",
    "Can Overfit: It can overfit especially when the data is high-dimensional or not clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c7ef28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8203309692671394\n",
      "Confusion Matrix:\n",
      " [[53  2  0  0  0  1  0]\n",
      " [15 19  8  2  0 10  8]\n",
      " [ 0  0 74  2  0  0  2]\n",
      " [ 0  0  2 56  0  0  0]\n",
      " [ 0  0  0  0 63  0  0]\n",
      " [ 2  5  0  0  0 46  3]\n",
      " [ 0  1  6  3  1  3 36]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.76      0.95      0.84        56\n",
      "      Normal_Weight       0.70      0.31      0.43        62\n",
      "     Obesity_Type_I       0.82      0.95      0.88        78\n",
      "    Obesity_Type_II       0.89      0.97      0.93        58\n",
      "   Obesity_Type_III       0.98      1.00      0.99        63\n",
      " Overweight_Level_I       0.77      0.82      0.79        56\n",
      "Overweight_Level_II       0.73      0.72      0.73        50\n",
      "\n",
      "           accuracy                           0.82       423\n",
      "          macro avg       0.81      0.82      0.80       423\n",
      "       weighted avg       0.81      0.82      0.80       423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Crear transformadores\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 4. Crear ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. Crear pipeline completo con KNN\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "# 6. Dividir datos en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y.values.ravel(), test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Entrenar modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 8. Evaluar modelo\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de Clasificación:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "647ee6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Mejores hiperparámetros: {'classifier__metric': 'manhattan', 'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}\n",
      "Mejor F1 score (validación): 0.8785808148883518\n",
      "\n",
      "F1 Score en test: 0.8717558146191585\n",
      "Confusion Matrix:\n",
      " [[54  1  0  0  0  1  0]\n",
      " [ 9 34  5  0  0 10  4]\n",
      " [ 0  0 73  2  0  1  2]\n",
      " [ 0  0  1 57  0  0  0]\n",
      " [ 0  0  0  0 63  0  0]\n",
      " [ 0  5  0  0  0 47  4]\n",
      " [ 0  1  2  0  1  3 43]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Insufficient_Weight       0.86      0.96      0.91        56\n",
      "      Normal_Weight       0.83      0.55      0.66        62\n",
      "     Obesity_Type_I       0.90      0.94      0.92        78\n",
      "    Obesity_Type_II       0.97      0.98      0.97        58\n",
      "   Obesity_Type_III       0.98      1.00      0.99        63\n",
      " Overweight_Level_I       0.76      0.84      0.80        56\n",
      "Overweight_Level_II       0.81      0.86      0.83        50\n",
      "\n",
      "           accuracy                           0.88       423\n",
      "          macro avg       0.87      0.88      0.87       423\n",
      "       weighted avg       0.88      0.88      0.87       423\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ultim\\anaconda3\\envs\\IDM\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.82493566 0.84001333 0.79426657 0.82029537 0.79056142 0.81111081\n",
      " 0.78379578 0.80917206 0.76757613 0.79995529        nan 0.87858081\n",
      "        nan 0.87288615        nan 0.86799686        nan 0.8594353\n",
      "        nan 0.85224345]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir la grilla de hiperparámetros para KNN\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# GridSearchCV con F1-score como métrica (micro, macro o weighted dependiendo de tus datos)\n",
    "grid_search = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid,\n",
    "    cv=5,  # validación cruzada de 5 folds\n",
    "    scoring='f1_weighted',  # usa 'f1_macro' o 'f1_micro' si prefieres\n",
    "    n_jobs=-1,  # usa todos los núcleos disponibles\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda en la rejilla\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Resultados del mejor modelo\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor F1 score (validación):\", grid_search.best_score_)\n",
    "# Evaluación en el conjunto de prueba\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"\\nF1 Score en test:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
